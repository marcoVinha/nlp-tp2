{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set value of CUDA_VISIBLE_DEVICES=\"\" to disable GPU\n",
    "import os\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_name = \"nilc-nlp/mac_morpho\"\n",
    "model_name = \"neuralmind/bert-base-portuguese-cased\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load dataset from HuggingFace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/marcovinha/nlp-tp2/.venv/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "dataset = load_dataset(dataset_name, trust_remote_code=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Label mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'PREP+PROADJ': 0,\n",
       " 'IN': 1,\n",
       " 'PREP+PRO-KS': 2,\n",
       " 'NPROP': 3,\n",
       " 'PREP+PROSUB': 4,\n",
       " 'KC': 5,\n",
       " 'PROPESS': 6,\n",
       " 'NUM': 7,\n",
       " 'PROADJ': 8,\n",
       " 'PREP+ART': 9,\n",
       " 'KS': 10,\n",
       " 'PRO-KS': 11,\n",
       " 'ADJ': 12,\n",
       " 'ADV-KS': 13,\n",
       " 'N': 14,\n",
       " 'PREP': 15,\n",
       " 'PROSUB': 16,\n",
       " 'PREP+PROPESS': 17,\n",
       " 'PDEN': 18,\n",
       " 'V': 19,\n",
       " 'PREP+ADV': 20,\n",
       " 'PCP': 21,\n",
       " 'CUR': 22,\n",
       " 'ADV': 23,\n",
       " 'PU': 24,\n",
       " 'ART': 25}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get unique labels\n",
    "labels = dataset[\"train\"].features[\"pos_tags\"].feature.names\n",
    "\n",
    "# Create a mapping\n",
    "label2id = {label: i for i, label in enumerate(labels)}\n",
    "id2label = {i: label for label, i in label2id.items()}\n",
    "\n",
    "label2id"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare tokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load from HuggingFace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\n",
    "    model_name,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tokenize dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_and_align_labels(examples):\n",
    "    tokenized_inputs = tokenizer(\n",
    "        examples[\"tokens\"], truncation=True, padding=True, is_split_into_words=True\n",
    "    )\n",
    "\n",
    "    labels = []\n",
    "    for i, label in enumerate(examples[\"pos_tags\"]):\n",
    "        word_ids = tokenized_inputs.word_ids(batch_index=i)  # Map tokens to words\n",
    "        aligned_labels = []\n",
    "        previous_word_id = None\n",
    "        for word_id in word_ids:\n",
    "            if word_id is None:\n",
    "                aligned_labels.append(-100)  # Ignore special tokens\n",
    "            elif word_id != previous_word_id:  # Start of a new word\n",
    "                aligned_labels.append(label[word_id])\n",
    "            else:\n",
    "                aligned_labels.append(-100)  # Ignore subword tokens\n",
    "            previous_word_id = word_id\n",
    "        labels.append(aligned_labels)\n",
    "\n",
    "    tokenized_inputs[\"labels\"] = labels\n",
    "    return tokenized_inputs\n",
    "\n",
    "\n",
    "# Tokenize the dataset\n",
    "tokenized_dataset = dataset.map(tokenize_and_align_labels, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import DataCollatorForTokenClassification\n",
    "\n",
    "data_collator = DataCollatorForTokenClassification(tokenizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fine tune model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForTokenClassification were not initialized from the model checkpoint at neuralmind/bert-base-portuguese-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForTokenClassification\n",
    "\n",
    "\n",
    "model = AutoModelForTokenClassification.from_pretrained(\n",
    "    model_name, num_labels=len(label2id), id2label=id2label, label2id=label2id\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fine tune model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining custom metric to evaluate model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def compute_metrics(p):\n",
    "    predictions, labels = p\n",
    "    # Remove ignored index (e.g., -100 used for padding)\n",
    "    predictions = np.argmax(predictions, axis=-1)\n",
    "\n",
    "    # Flatten the lists of predictions and labels\n",
    "    true_labels = labels.flatten()\n",
    "    pred_labels = predictions.flatten()\n",
    "\n",
    "    # Mask the -100 labels (ignore them)\n",
    "    mask = true_labels != -100\n",
    "    true_labels = true_labels[mask]\n",
    "    pred_labels = pred_labels[mask]\n",
    "\n",
    "    # Calculate overall accuracy\n",
    "    overall_accuracy = accuracy_score(true_labels, pred_labels)\n",
    "\n",
    "    # Calculate per-tag accuracy\n",
    "    unique_tags = np.unique(true_labels)\n",
    "    per_tag_accuracy = {}\n",
    "    for tag in unique_tags:\n",
    "        # Mask for the current tag\n",
    "        tag_mask = true_labels == tag\n",
    "        tag_true = true_labels[tag_mask]\n",
    "        tag_pred = pred_labels[tag_mask]\n",
    "\n",
    "        # Calculate accuracy for this tag\n",
    "        tag_accuracy = accuracy_score(tag_true, tag_pred)\n",
    "        per_tag_accuracy[id2label[tag]] = tag_accuracy\n",
    "\n",
    "    # Return the overall accuracy and per-tag accuracy\n",
    "    return {\"overall_accuracy\": overall_accuracy, \"per_tag_accuracy\": per_tag_accuracy}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/marcovinha/nlp-tp2/.venv/lib/python3.10/site-packages/transformers/training_args.py:1575: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ðŸ¤— Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from transformers import TrainingArguments, Trainer\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\".results\",\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    learning_rate=5e-5,\n",
    "    num_train_epochs=3,\n",
    "    save_strategy=\"epoch\",\n",
    "    use_cpu=True,\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_dataset[\"train\"],\n",
    "    eval_dataset=tokenized_dataset[\"validation\"],\n",
    "    data_collator=data_collator,\n",
    "    processing_class=tokenizer,\n",
    "    compute_metrics=compute_metrics,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Against test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1249' max='1249' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1249/1249 25:37]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 3.3340036869049072, 'eval_model_preparation_time': 0.0067, 'eval_overall_accuracy': 0.02604093668884865, 'eval_per_tag_accuracy': {'PREP+PROADJ': 0.11003236245954692, 'IN': 0.0, 'PREP+PRO-KS': 0.0, 'NPROP': 0.03978413654618474, 'PREP+PROSUB': 0.0, 'KC': 0.0006621054954756124, 'PROPESS': 0.014603616133518776, 'NUM': 0.01652892561983471, 'PROADJ': 0.00116993272886809, 'PREP+ART': 0.1415989822878951, 'KS': 0.02955082742316785, 'PRO-KS': 0.006378132118451025, 'ADJ': 0.013911620294599018, 'ADV-KS': 0.05217391304347826, 'N': 0.013299764654370314, 'PREP': 0.010966742162355466, 'PROSUB': 0.05679642629227824, 'PREP+PROPESS': 0.047619047619047616, 'PDEN': 0.03021978021978022, 'V': 0.017604383339252194, 'PREP+ADV': 0.0, 'PCP': 0.2662087912087912, 'CUR': 0.0, 'ADV': 0.018912963643040764, 'PU': 7.43383883437407e-05, 'ART': 0.0}, 'eval_runtime': 1539.395, 'eval_samples_per_second': 6.488, 'eval_steps_per_second': 0.811}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('./fine_tuned_model/tokenizer_config.json',\n",
       " './fine_tuned_model/special_tokens_map.json',\n",
       " './fine_tuned_model/vocab.txt',\n",
       " './fine_tuned_model/added_tokens.json',\n",
       " './fine_tuned_model/tokenizer.json')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = trainer.evaluate(\n",
    "    # tokenized_dataset[\"test\"].shuffle(seed=42).select(range(0, 150))\n",
    "    tokenized_dataset[\"test\"]\n",
    ")\n",
    "print(results)\n",
    "\n",
    "model.save_pretrained(\"./fine_tuned_model\")\n",
    "tokenizer.save_pretrained(\"./fine_tuned_model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Against another model trained on the same dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertForTokenClassification(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(29794, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-11): 12 x BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSdpaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (classifier): Linear(in_features=768, out_features=27, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load `lisaterumi/postagger-portuguese` from hugging face and store in a `competitor_model` variable\n",
    "\n",
    "from transformers import BertForTokenClassification\n",
    "\n",
    "competitor_model = BertForTokenClassification.from_pretrained(\n",
    "    \"lisaterumi/postagger-portuguese\"\n",
    ")\n",
    "competitor_tokenizer = AutoTokenizer.from_pretrained(\"lisaterumi/postagger-portuguese\")\n",
    "\n",
    "competitor_model.to(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 37948/37948 [00:07<00:00, 5115.60 examples/s]\n",
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9987/9987 [00:02<00:00, 4796.42 examples/s]\n",
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1997/1997 [00:00<00:00, 4906.03 examples/s]\n"
     ]
    }
   ],
   "source": [
    "def tokenize_and_align_labels_for_comparison(examples):\n",
    "    tokenized_inputs = competitor_tokenizer(\n",
    "        examples[\"tokens\"],\n",
    "        truncation=True,\n",
    "        is_split_into_words=True,\n",
    "        padding=\"max_length\",\n",
    "        max_length=128,\n",
    "    )\n",
    "\n",
    "    # Align labels with tokenized inputs\n",
    "    labels = []\n",
    "    for i, label in enumerate(examples[\"labels\"]):\n",
    "        word_ids = tokenized_inputs.word_ids(batch_index=i)\n",
    "        aligned_labels = [\n",
    "            -100 if word_id is None else label[word_id] for word_id in word_ids\n",
    "        ]\n",
    "        labels.append(aligned_labels)\n",
    "\n",
    "    tokenized_inputs[\"labels\"] = labels\n",
    "    return tokenized_inputs\n",
    "\n",
    "\n",
    "tokenized_test_dataset_comparison = tokenized_dataset.map(\n",
    "    tokenize_and_align_labels_for_comparison, batched=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/marcovinha/nlp-tp2/.venv/lib/python3.10/site-packages/transformers/training_args.py:1575: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ðŸ¤— Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the `competitor_model` using the same `compute_metrics` function and the same `tokenized_dataset[\"test\"]` dataset\n",
    "\n",
    "# Define dummy training arguments (just for evaluation)\n",
    "dummy_training_args = TrainingArguments(\n",
    "    output_dir=\"./results\",\n",
    "    logging_dir=\"./logs\",\n",
    "    do_train=False,\n",
    "    do_eval=True,\n",
    "    evaluation_strategy=\"no\",\n",
    ")\n",
    "\n",
    "# Create a Trainer for the comparison model\n",
    "competitor_trainer = Trainer(\n",
    "    model=competitor_model,\n",
    "    args=training_args,\n",
    "    eval_dataset=tokenized_test_dataset_comparison[\"validation\"],\n",
    "    processing_class=competitor_tokenizer,\n",
    "    compute_metrics=compute_metrics,  # Use the same custom metric function\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1249' max='1249' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1249/1249 22:40]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 10.260217666625977, 'eval_model_preparation_time': 0.0072, 'eval_overall_accuracy': 0.05898346889038964, 'eval_per_tag_accuracy': {'PREP+PROADJ': 0.0, 'IN': 0.011904761904761904, 'PREP+PRO-KS': 0.0, 'NPROP': 0.0008249777890595254, 'PREP+PROSUB': 0.07692307692307693, 'KC': 0.011541072640868975, 'PROPESS': 0.013399813025864755, 'NUM': 0.02203742203742204, 'PROADJ': 0.018421052631578946, 'PREP+ART': 0.12725667189952905, 'KS': 0.04515225761288064, 'PRO-KS': 0.041666666666666664, 'ADJ': 0.011773940345368918, 'ADV-KS': 0.09210526315789473, 'N': 0.15725369638413117, 'PREP': 0.011693500998942296, 'PROSUB': 0.006422607578676943, 'PREP+PROPESS': 0.0, 'PDEN': 0.04713493530499076, 'V': 0.00038580246913580245, 'PREP+ADV': 0.0, 'PCP': 0.001984689537850865, 'CUR': 0.0, 'ADV': 0.0014207068016338128, 'PU': 0.1326202645028716, 'ART': 0.0}, 'eval_runtime': 1361.2956, 'eval_samples_per_second': 7.336, 'eval_steps_per_second': 0.918}\n"
     ]
    }
   ],
   "source": [
    "eval_results_comparison = competitor_trainer.evaluate(\n",
    "    tokenized_test_dataset_comparison[\"test\"]\n",
    ")\n",
    "\n",
    "print(eval_results_comparison)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
