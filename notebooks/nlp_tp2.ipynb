{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fine tuning BERTimbau to perform Parts of Speech Tagging\n",
    "\n",
    "This notebook fine tunes a BERTimbau model (`neuralmind/bert-base-portuguese-cased`, 110M parameters) in the Mac-Morpho dataset to perform a Parts of Speech Tagging (POS Tagging) task in portuguese.\n",
    "\n",
    "The evaluation of this model's performance consists in:\n",
    "- Calculating three different metrics on the test dataset:\n",
    "    - Macro precision\n",
    "    - Weighted precision\n",
    "    - Per-class precision\n",
    "- Comparing these metrics with the ones obtained by a competitor model:\n",
    "    - The competitor model is the `lisaterumi/postagger-portuguese`\n",
    "    - This model is also a BERTimbau-based model\n",
    "    - This model is also fine tuned to perform POS Tagging in the Mac-Morpho dataset\n",
    "\n",
    "In practice, the model we'll fine tune aims to reproduce the results of the `lisaterumi/postagger-portuguese` model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_name = \"nilc-nlp/mac_morpho\"\n",
    "model_name = \"neuralmind/bert-base-portuguese-cased\"\n",
    "competitor_model_name = \"lisaterumi/postagger-portuguese\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The dataset\n",
    "\n",
    "From the official Mac-Morpho [web-page](http://nilc.icmc.usp.br/macmorpho/):\n",
    "\n",
    "> Mac-Morpho is a corpus of Brazilian Portuguese texts annotated with part-of-speech tags. Its first version was released in 2003, and since then, two revisions have been made in order to improve the quality of the resource.\n",
    "\n",
    "According to the [dataset manual](http://nilc.icmc.usp.br/macmorpho/macmorpho-manual.pdf), it is already split in a train, a validation and a test sub-sets, and it contains a total of 27 possible classes/tags. The following table shows the classes in our dataset:\n",
    "\n",
    "\n",
    "| Tag |  Meaning (grammatical class in portuguese)|\n",
    "| ------------------- | ------------------- |\n",
    "|  ADJ |  Adjetivo |\n",
    "|  ADV |  Adv√©rbio |\n",
    "|  ADV-KS |  Adv√©rbio conjuntivo subordinado  |\n",
    "|  ADV-KS-REL |   Adv√©rbio relativo subordinado |\n",
    "|  ART |  Artigo  |\n",
    "|  CUR |  Moeda  |\n",
    "|  IN |  Interjei√ß√£o |\n",
    "|  KC |  Conjun√ß√£o coordenativa |\n",
    "|  KS |  Conjun√ß√£o subordinativa |\n",
    "|  N |  Substantivo |\n",
    "|  NPROP | Substantivo pr√≥prio |\n",
    "|  NUM |  N√∫mero |\n",
    "|  PCP |  Partic√≠pio |\n",
    "|  PDEN |  Palavra denotativa |\n",
    "|  PREP |  Preposi√ß√£o |\n",
    "|  PROADJ |  Pronome Adjetivo |\n",
    "|  PRO-KS |  Pronome conjuntivo subordinado |\n",
    "|  PRO-KS-REL |  Pronome relativo conectivo subordinado |\n",
    "|  PROPESS |  Pronome pessoal |\n",
    "|  PROSUB |  Pronome nominal |\n",
    "|  V | Verbo |\n",
    "|  VAUX  | Verbo auxiliar |\n",
    "\n",
    "Next, we'll prepare the dataset for the fine tuning task.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load dataset from HuggingFace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/nlp-tp2/.venv/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "dataset = load_dataset(dataset_name, trust_remote_code=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating maps from label to ID and vice-versa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'PREP+PROADJ': 0,\n",
       " 'IN': 1,\n",
       " 'PREP+PRO-KS': 2,\n",
       " 'NPROP': 3,\n",
       " 'PREP+PROSUB': 4,\n",
       " 'KC': 5,\n",
       " 'PROPESS': 6,\n",
       " 'NUM': 7,\n",
       " 'PROADJ': 8,\n",
       " 'PREP+ART': 9,\n",
       " 'KS': 10,\n",
       " 'PRO-KS': 11,\n",
       " 'ADJ': 12,\n",
       " 'ADV-KS': 13,\n",
       " 'N': 14,\n",
       " 'PREP': 15,\n",
       " 'PROSUB': 16,\n",
       " 'PREP+PROPESS': 17,\n",
       " 'PDEN': 18,\n",
       " 'V': 19,\n",
       " 'PREP+ADV': 20,\n",
       " 'PCP': 21,\n",
       " 'CUR': 22,\n",
       " 'ADV': 23,\n",
       " 'PU': 24,\n",
       " 'ART': 25}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get unique labels\n",
    "labels = dataset[\"train\"].features[\"pos_tags\"].feature.names\n",
    "\n",
    "# Create the mappings\n",
    "label2id = {label: i for i, label in enumerate(labels)}\n",
    "id2label = {i: label for label, i in label2id.items()}\n",
    "\n",
    "label2id"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the BERTimbau tokenizer from HuggingFace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\n",
    "    model_name,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import DataCollatorForTokenClassification\n",
    "\n",
    "data_collator = DataCollatorForTokenClassification(tokenizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tokenize and align dataset\n",
    "\n",
    "The tokenization process (transforming words/tokens in numbers) is an already known sub-task in NLP tasks, so we'll skip any explanations. But one additional thing we'll do is **aligning** the labels with the correct tokens we want to classify.\n",
    "\n",
    "Aligning, in this context, means *knowing what subwords/tokens of a word we want to tag*. When you tokenize a sentence, especially using subword tokenizers (which is the case with the tokenizer we're using), the sentence is split into subword tokens. Because of this, we need to ensure that the labels are correctly associated with these tokens. This is where label alignment comes into play.\n",
    "\n",
    "In our dataset, each word has a single label, but tokenization may result in subwords. In the end of our tokenization process, the number of tokens often exceeds the number of original words. For example:\n",
    "- Imagine our labels look something like: `label2id = {\"NOUN\": 0, \"VERB\": 1, ...}`\n",
    "- Now imagine that we're trying to classify the word `playing` into a `VERB`\n",
    "- When we tokenized THE word, it is broken into **two tokens**: `[\"play\", \"ing\"]`\n",
    "- What should we tag as a `VERB`: `play`, or `ing`?\n",
    "\n",
    "In this case, we'll fix this by \"aligning\" our dataset:\n",
    "1. The first token of a word (in our case, `play`) will be tagged with the original word's label (in our case, `VERB`, with value `1`).\n",
    "2. The following tokens, will be ignored if we assign a special value/class to it. Typically, when we assign the value of `-100`, our model is already able to ignore the token, excluding it from the loss function calculation during training.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map:   0%|          | 0/1997 [00:00<?, ? examples/s]Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n",
      "Map: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1997/1997 [00:00<00:00, 5899.49 examples/s]\n"
     ]
    }
   ],
   "source": [
    "def tokenize_and_align_labels(examples):\n",
    "    tokenized_inputs = tokenizer(\n",
    "        examples[\"tokens\"], truncation=True, padding=True, is_split_into_words=True\n",
    "    )\n",
    "\n",
    "    labels = []\n",
    "    for i, label in enumerate(examples[\"pos_tags\"]):\n",
    "        word_ids = tokenized_inputs.word_ids(batch_index=i)\n",
    "        aligned_labels = []\n",
    "        previous_word_id = None\n",
    "        for word_id in word_ids:\n",
    "            if word_id is None:\n",
    "                aligned_labels.append(-100)\n",
    "            elif word_id != previous_word_id:\n",
    "                aligned_labels.append(label[word_id])\n",
    "            else:\n",
    "                aligned_labels.append(-100)\n",
    "            previous_word_id = word_id\n",
    "        labels.append(aligned_labels)\n",
    "\n",
    "    tokenized_inputs[\"labels\"] = labels\n",
    "    return tokenized_inputs\n",
    "\n",
    "\n",
    "tokenized_dataset = dataset.map(tokenize_and_align_labels, batched=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fine tune our model\n",
    "\n",
    "We'll fine tune our model for only $5$ epochs, and we'll use a learning rate of $5\\mathrm{e}{-5}$. Our dataset is split in train (37948 samples), validation (1997 samples) and test (9987 samples) sub-sets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download model from HuggingFace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForTokenClassification were not initialized from the model checkpoint at neuralmind/bert-base-portuguese-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "BertForTokenClassification(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(29794, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-11): 12 x BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSdpaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (classifier): Linear(in_features=768, out_features=26, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import AutoModelForTokenClassification\n",
    "\n",
    "\n",
    "model = AutoModelForTokenClassification.from_pretrained(\n",
    "    model_name, num_labels=len(label2id), id2label=id2label, label2id=label2id\n",
    ")\n",
    "\n",
    "model.to(\"cuda\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define fine tuning routine"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining custom metrics to evaluate model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_score\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def compute_metrics(p):\n",
    "    predictions, labels = p\n",
    "\n",
    "    # Get predicted labels by taking argmax\n",
    "    predictions = np.argmax(predictions, axis=-1)\n",
    "\n",
    "    # Flatten and filter out ignored tokens (-100)\n",
    "    true_labels = labels.flatten()\n",
    "    pred_labels = predictions.flatten()\n",
    "    mask = true_labels != -100\n",
    "    true_labels = true_labels[mask]\n",
    "    pred_labels = pred_labels[mask]\n",
    "\n",
    "    # Compute precision\n",
    "    macro_precision = precision_score(\n",
    "        true_labels, pred_labels, average=\"macro\", zero_division=0\n",
    "    )\n",
    "    weighted_precision = precision_score(\n",
    "        true_labels, pred_labels, average=\"weighted\", zero_division=0\n",
    "    )\n",
    "    per_class_precision = precision_score(\n",
    "        true_labels, pred_labels, average=None, zero_division=0\n",
    "    )\n",
    "\n",
    "    # Map class indices to precision values\n",
    "    unique_tags = np.unique(true_labels)\n",
    "    per_class_precision_dict = {\n",
    "        id2label[int(tag)]: float(per_class_precision[i])\n",
    "        for i, tag in enumerate(unique_tags)\n",
    "    }\n",
    "\n",
    "    return {\n",
    "        \"macro_precision\": macro_precision,\n",
    "        \"weighted_precision\": weighted_precision,\n",
    "        \"per_class_precision\": per_class_precision_dict,\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/nlp-tp2/.venv/lib/python3.10/site-packages/transformers/training_args.py:1575: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ü§ó Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from transformers import TrainingArguments, Trainer\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\".results\",\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    learning_rate=5e-5,\n",
    "    num_train_epochs=5,\n",
    "    save_strategy=\"epoch\",\n",
    "    use_cpu=False,\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_dataset[\"train\"],\n",
    "    eval_dataset=tokenized_dataset[\"validation\"],\n",
    "    data_collator=data_collator,\n",
    "    processing_class=tokenizer,\n",
    "    compute_metrics=compute_metrics,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='23720' max='23720' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [23720/23720 27:27, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Macro Precision</th>\n",
       "      <th>Weighted Precision</th>\n",
       "      <th>Per Class Precision</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.065700</td>\n",
       "      <td>0.063025</td>\n",
       "      <td>0.945177</td>\n",
       "      <td>0.983040</td>\n",
       "      <td>{'PREP+PROADJ': 1.0, 'IN': 0.5714285714285714, 'PREP+PRO-KS': 0.7692307692307693, 'NPROP': 0.9748031496062992, 'PREP+PROSUB': 0.8846153846153846, 'KC': 0.9902386117136659, 'PROPESS': 0.9953379953379954, 'NUM': 0.9811046511627907, 'PROADJ': 0.9800664451827242, 'PREP+ART': 0.990139687756779, 'KS': 0.9141630901287554, 'PRO-KS': 0.9337748344370861, 'ADJ': 0.9733629300776915, 'ADV-KS': 0.9, 'N': 0.9832671241121945, 'PREP': 0.9810874704491725, 'PROSUB': 0.92, 'PREP+PROPESS': 1.0, 'PDEN': 0.9377777777777778, 'V': 0.9969796123835892, 'PREP+ADV': 1.0, 'PCP': 0.977326968973747, 'CUR': 0.991304347826087, 'ADV': 0.9404255319148936, 'PU': 0.9991275519106613, 'ART': 0.9890335846470185}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.047200</td>\n",
       "      <td>0.061211</td>\n",
       "      <td>0.943762</td>\n",
       "      <td>0.983468</td>\n",
       "      <td>{'PREP+PROADJ': 1.0, 'IN': 0.7777777777777778, 'PREP+PRO-KS': 0.7272727272727273, 'NPROP': 0.9777019937040924, 'PREP+PROSUB': 0.84, 'KC': 0.993485342019544, 'PROPESS': 0.9884259259259259, 'NUM': 0.9715099715099715, 'PROADJ': 0.9798319327731092, 'PREP+ART': 0.9901477832512315, 'KS': 0.9271523178807947, 'PRO-KS': 0.9282608695652174, 'ADJ': 0.9760978321289605, 'ADV-KS': 0.8235294117647058, 'N': 0.9835277143200674, 'PREP': 0.9870267407995764, 'PROSUB': 0.9183673469387755, 'PREP+PROPESS': 1.0, 'PDEN': 0.8588235294117647, 'V': 0.9967328474491078, 'PREP+ADV': 1.0, 'PCP': 0.9842233009708737, 'CUR': 0.991304347826087, 'ADV': 0.9257322175732218, 'PU': 0.999825388510564, 'ART': 0.9910622206943966}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.027800</td>\n",
       "      <td>0.066428</td>\n",
       "      <td>0.953270</td>\n",
       "      <td>0.984214</td>\n",
       "      <td>{'PREP+PROADJ': 1.0, 'IN': 0.9, 'PREP+PRO-KS': 0.7272727272727273, 'NPROP': 0.9704816157431383, 'PREP+PROSUB': 0.88, 'KC': 0.991313789359392, 'PROPESS': 0.9953379953379954, 'NUM': 0.9797687861271677, 'PROADJ': 0.9915397631133672, 'PREP+ART': 0.9933856965688301, 'KS': 0.9375, 'PRO-KS': 0.9265658747300216, 'ADJ': 0.9693821760524877, 'ADV-KS': 0.8235294117647058, 'N': 0.9864570737605804, 'PREP': 0.9854458851548028, 'PROSUB': 0.9169960474308301, 'PREP+PROPESS': 1.0, 'PDEN': 0.9141630901287554, 'V': 0.9964815280221161, 'PREP+ADV': 1.0, 'PCP': 0.9841656516443362, 'CUR': 0.991304347826087, 'ADV': 0.9314928425357873, 'PU': 1.0, 'ART': 0.9924242424242424}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.014200</td>\n",
       "      <td>0.078415</td>\n",
       "      <td>0.960127</td>\n",
       "      <td>0.984880</td>\n",
       "      <td>{'PREP+PROADJ': 1.0, 'IN': 1.0, 'PREP+PRO-KS': 0.7692307692307693, 'NPROP': 0.9744725188851263, 'PREP+PROSUB': 0.875, 'KC': 0.9892241379310345, 'PROPESS': 0.9930394431554525, 'NUM': 0.9769784172661871, 'PROADJ': 0.9784768211920529, 'PREP+ART': 0.9933938893476466, 'KS': 0.9317180616740088, 'PRO-KS': 0.9299781181619255, 'ADJ': 0.9705240174672489, 'ADV-KS': 0.8529411764705882, 'N': 0.9859869533703793, 'PREP': 0.9872847682119206, 'PROSUB': 0.9338842975206612, 'PREP+PROPESS': 1.0, 'PDEN': 0.9166666666666666, 'V': 0.9969841668760995, 'PREP+ADV': 1.0, 'PCP': 0.9784172661870504, 'CUR': 0.991304347826087, 'ADV': 0.9446764091858038, 'PU': 1.0, 'ART': 0.9931129476584022}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.006000</td>\n",
       "      <td>0.087644</td>\n",
       "      <td>0.956394</td>\n",
       "      <td>0.984432</td>\n",
       "      <td>{'PREP+PROADJ': 1.0, 'IN': 1.0, 'PREP+PRO-KS': 0.7692307692307693, 'NPROP': 0.9734582357533177, 'PREP+PROSUB': 0.8461538461538461, 'KC': 0.9870828848223897, 'PROPESS': 0.9976580796252927, 'NUM': 0.9840579710144928, 'PROADJ': 0.978405315614618, 'PREP+ART': 0.9921681780708986, 'KS': 0.9292035398230089, 'PRO-KS': 0.9240780911062907, 'ADJ': 0.967444384156267, 'ADV-KS': 0.8484848484848485, 'N': 0.9866989117291415, 'PREP': 0.9864577801380775, 'PROSUB': 0.930327868852459, 'PREP+PROPESS': 0.95, 'PDEN': 0.9156118143459916, 'V': 0.9969841668760995, 'PREP+ADV': 1.0, 'PCP': 0.9819277108433735, 'CUR': 0.991304347826087, 'ADV': 0.9367219917012448, 'PU': 1.0, 'ART': 0.9927760577915377}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=23720, training_loss=0.037826870766297156, metrics={'train_runtime': 1647.6609, 'train_samples_per_second': 115.157, 'train_steps_per_second': 14.396, 'total_flos': 1.835607201292267e+16, 'train_loss': 0.037826870766297156, 'epoch': 5.0})"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Against test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1249' max='1249' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1249/1249 00:21]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 0.12814809381961823,\n",
       " 'eval_macro_precision': 0.9340724314143004,\n",
       " 'eval_weighted_precision': 0.9806122516924665,\n",
       " 'eval_per_class_precision': {'PREP+PROADJ': 0.9935275080906149,\n",
       "  'IN': 0.4934210526315789,\n",
       "  'PREP+PRO-KS': 0.782608695652174,\n",
       "  'NPROP': 0.9764071029679362,\n",
       "  'PREP+PROSUB': 0.8972602739726028,\n",
       "  'KC': 0.9810112607639656,\n",
       "  'PROPESS': 0.9923371647509579,\n",
       "  'NUM': 0.9763811048839072,\n",
       "  'PROADJ': 0.9676479160594579,\n",
       "  'PREP+ART': 0.9928452415956092,\n",
       "  'KS': 0.9367909238249594,\n",
       "  'PRO-KS': 0.9217238346525946,\n",
       "  'ADJ': 0.9612330686595049,\n",
       "  'ADV-KS': 0.8312236286919831,\n",
       "  'N': 0.9819668981417945,\n",
       "  'PREP': 0.9811835935181338,\n",
       "  'PROSUB': 0.9217619986850756,\n",
       "  'PREP+PROPESS': 1.0,\n",
       "  'PDEN': 0.8748890860692103,\n",
       "  'V': 0.9954810865701955,\n",
       "  'PREP+ADV': 0.9375,\n",
       "  'PCP': 0.972482113373693,\n",
       "  'CUR': 0.9966216216216216,\n",
       "  'ADV': 0.930755064456722,\n",
       "  'PU': 0.9997398349810451,\n",
       "  'ART': 0.989083142156475},\n",
       " 'eval_runtime': 22.0823,\n",
       " 'eval_samples_per_second': 452.263,\n",
       " 'eval_steps_per_second': 56.561,\n",
       " 'epoch': 5.0}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_results = trainer.evaluate(tokenized_dataset[\"test\"])\n",
    "\n",
    "model_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Against the `lisaterumi/postagger-portuguese` model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertForTokenClassification\n",
    "\n",
    "competitor_model = BertForTokenClassification.from_pretrained(competitor_model_name)\n",
    "competitor_model.to(\"cuda\")\n",
    "\n",
    "competitor_tokenizer = AutoTokenizer.from_pretrained(competitor_model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 9987/9987 [00:01<00:00, 5924.75 examples/s]\n",
      "Map: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1997/1997 [00:00<00:00, 5952.50 examples/s]\n"
     ]
    }
   ],
   "source": [
    "def tokenize_and_align_labels_for_comparison(examples):\n",
    "    tokenized_inputs = competitor_tokenizer(\n",
    "        examples[\"tokens\"],\n",
    "        truncation=True,\n",
    "        is_split_into_words=True,\n",
    "        padding=\"max_length\",\n",
    "        max_length=128,\n",
    "    )\n",
    "\n",
    "    # Align labels with tokenized inputs\n",
    "    labels = []\n",
    "    for i, label in enumerate(examples[\"labels\"]):\n",
    "        word_ids = tokenized_inputs.word_ids(batch_index=i)\n",
    "        aligned_labels = [\n",
    "            -100 if word_id is None else label[word_id] for word_id in word_ids\n",
    "        ]\n",
    "        labels.append(aligned_labels)\n",
    "\n",
    "    tokenized_inputs[\"labels\"] = labels\n",
    "    return tokenized_inputs\n",
    "\n",
    "\n",
    "tokenized_test_dataset_comparison = tokenized_dataset.map(\n",
    "    tokenize_and_align_labels_for_comparison, batched=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/nlp-tp2/.venv/lib/python3.10/site-packages/transformers/training_args.py:1575: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ü§ó Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# We don't need to train our model, so we'll use\n",
    "# the Trainer API with dummy values\n",
    "dummy_training_args = TrainingArguments(\n",
    "    output_dir=\"./results\",\n",
    "    logging_dir=\"./logs\",\n",
    "    do_train=False,\n",
    "    do_eval=True,\n",
    "    evaluation_strategy=\"no\",\n",
    "    use_cpu=False,\n",
    ")\n",
    "\n",
    "competitor_trainer = Trainer(\n",
    "    model=competitor_model,\n",
    "    args=dummy_training_args,\n",
    "    eval_dataset=tokenized_test_dataset_comparison[\"validation\"],\n",
    "    processing_class=competitor_tokenizer,\n",
    "    compute_metrics=compute_metrics,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1249' max='1249' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1249/1249 00:18]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 10.26021671295166,\n",
       " 'eval_model_preparation_time': 0.0042,\n",
       " 'eval_macro_precision': 0.034122055046705034,\n",
       " 'eval_weighted_precision': 0.07739469736230463,\n",
       " 'eval_per_class_precision': {'PREP+PROADJ': 0.0,\n",
       "  'IN': 0.0005425935973955507,\n",
       "  'PREP+PRO-KS': 0.0,\n",
       "  'NPROP': 0.06532663316582915,\n",
       "  'PREP+PROSUB': 0.0005937654626422563,\n",
       "  'KC': 0.05448717948717949,\n",
       "  'PROPESS': 0.01650038372985418,\n",
       "  'NUM': 0.011442141623488774,\n",
       "  'PROADJ': 0.018442622950819672,\n",
       "  'PREP+ART': 0.05470727180698498,\n",
       "  'KS': 0.009498564170532362,\n",
       "  'PRO-KS': 0.022401433691756272,\n",
       "  'ADJ': 0.049019607843137254,\n",
       "  'ADV-KS': 0.002431681333950903,\n",
       "  'N': 0.1430054848500985,\n",
       "  'PREP': 0.08588692274492879,\n",
       "  'PROSUB': 0.08333333333333333,\n",
       "  'PREP+PROPESS': 0.0,\n",
       "  'PDEN': 0.0050009805844283195,\n",
       "  'V': 0.0761904761904762,\n",
       "  'PREP+ADV': 0.0,\n",
       "  'PCP': 0.006422018348623854,\n",
       "  'CUR': 0.0,\n",
       "  'ADV': 0.058823529411764705,\n",
       "  'PU': 0.12311680688710624,\n",
       "  'ART': 0.0},\n",
       " 'eval_runtime': 18.6117,\n",
       " 'eval_samples_per_second': 536.599,\n",
       " 'eval_steps_per_second': 67.108}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_results_comparison = competitor_trainer.evaluate(\n",
    "    tokenized_test_dataset_comparison[\"test\"]\n",
    ")\n",
    "\n",
    "eval_results_comparison"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
