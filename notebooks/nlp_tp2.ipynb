{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_name = \"nilc-nlp/mac_morpho\"\n",
    "model_name = \"neuralmind/bert-base-portuguese-cased\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load dataset from HuggingFace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/nlp-tp2/.venv/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "dataset = load_dataset(dataset_name, trust_remote_code=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Label mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'PREP+PROADJ': 0,\n",
       " 'IN': 1,\n",
       " 'PREP+PRO-KS': 2,\n",
       " 'NPROP': 3,\n",
       " 'PREP+PROSUB': 4,\n",
       " 'KC': 5,\n",
       " 'PROPESS': 6,\n",
       " 'NUM': 7,\n",
       " 'PROADJ': 8,\n",
       " 'PREP+ART': 9,\n",
       " 'KS': 10,\n",
       " 'PRO-KS': 11,\n",
       " 'ADJ': 12,\n",
       " 'ADV-KS': 13,\n",
       " 'N': 14,\n",
       " 'PREP': 15,\n",
       " 'PROSUB': 16,\n",
       " 'PREP+PROPESS': 17,\n",
       " 'PDEN': 18,\n",
       " 'V': 19,\n",
       " 'PREP+ADV': 20,\n",
       " 'PCP': 21,\n",
       " 'CUR': 22,\n",
       " 'ADV': 23,\n",
       " 'PU': 24,\n",
       " 'ART': 25}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get unique labels\n",
    "labels = dataset[\"train\"].features[\"pos_tags\"].feature.names\n",
    "\n",
    "# Create a mapping\n",
    "label2id = {label: i for i, label in enumerate(labels)}\n",
    "id2label = {i: label for label, i in label2id.items()}\n",
    "\n",
    "label2id"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare tokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load from HuggingFace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\n",
    "    model_name,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tokenize dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map:   0%|          | 0/9987 [00:00<?, ? examples/s]Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n",
      "Map: 100%|██████████| 9987/9987 [00:01<00:00, 6937.79 examples/s]\n"
     ]
    }
   ],
   "source": [
    "def tokenize_and_align_labels(examples):\n",
    "    tokenized_inputs = tokenizer(\n",
    "        examples[\"tokens\"], truncation=True, padding=True, is_split_into_words=True\n",
    "    )\n",
    "\n",
    "    labels = []\n",
    "    for i, label in enumerate(examples[\"pos_tags\"]):\n",
    "        word_ids = tokenized_inputs.word_ids(batch_index=i)  # Map tokens to words\n",
    "        aligned_labels = []\n",
    "        previous_word_id = None\n",
    "        for word_id in word_ids:\n",
    "            if word_id is None:\n",
    "                aligned_labels.append(-100)  # Ignore special tokens\n",
    "            elif word_id != previous_word_id:  # Start of a new word\n",
    "                aligned_labels.append(label[word_id])\n",
    "            else:\n",
    "                aligned_labels.append(-100)  # Ignore subword tokens\n",
    "            previous_word_id = word_id\n",
    "        labels.append(aligned_labels)\n",
    "\n",
    "    tokenized_inputs[\"labels\"] = labels\n",
    "    return tokenized_inputs\n",
    "\n",
    "\n",
    "# Tokenize the dataset\n",
    "tokenized_dataset = dataset.map(tokenize_and_align_labels, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import DataCollatorForTokenClassification\n",
    "\n",
    "data_collator = DataCollatorForTokenClassification(tokenizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fine tune model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForTokenClassification were not initialized from the model checkpoint at neuralmind/bert-base-portuguese-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "BertForTokenClassification(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(29794, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-11): 12 x BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSdpaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (classifier): Linear(in_features=768, out_features=26, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import AutoModelForTokenClassification\n",
    "\n",
    "\n",
    "model = AutoModelForTokenClassification.from_pretrained(\n",
    "    model_name, num_labels=len(label2id), id2label=id2label, label2id=label2id\n",
    ")\n",
    "\n",
    "model.to(\"cuda\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fine tune model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining custom metrics to evaluate model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_score\n",
    "import numpy as np\n",
    "\n",
    "def compute_metrics(p):\n",
    "    predictions, labels = p\n",
    "\n",
    "    # Get predicted labels by taking argmax\n",
    "    predictions = np.argmax(predictions, axis=-1)\n",
    "    \n",
    "    # Flatten and filter out ignored tokens (-100)\n",
    "    true_labels = labels.flatten()\n",
    "    pred_labels = predictions.flatten()\n",
    "    mask = true_labels != -100\n",
    "    true_labels = true_labels[mask]\n",
    "    pred_labels = pred_labels[mask]\n",
    "    \n",
    "    # Compute precision\n",
    "    macro_precision = precision_score(true_labels, pred_labels, average=\"macro\", zero_division=0)\n",
    "    weighted_precision = precision_score(true_labels, pred_labels, average=\"weighted\", zero_division=0)\n",
    "    per_class_precision = precision_score(true_labels, pred_labels, average=None, zero_division=0)\n",
    "\n",
    "    # Map class indices to precision values\n",
    "    unique_tags = np.unique(true_labels)\n",
    "    per_class_precision_dict = {id2label[int(tag)]: float(per_class_precision[i]) for i, tag in enumerate(unique_tags)}\n",
    "    \n",
    "    return {\n",
    "        \"macro_precision\": macro_precision,\n",
    "        \"weighted_precision\": weighted_precision,\n",
    "        \"per_class_precision\": per_class_precision_dict,\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/nlp-tp2/.venv/lib/python3.10/site-packages/transformers/training_args.py:1575: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from transformers import TrainingArguments, Trainer\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\".results\",\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    learning_rate=5e-5,\n",
    "    num_train_epochs=3,\n",
    "    save_strategy=\"epoch\",\n",
    "    use_cpu=False,\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_dataset[\"train\"],\n",
    "    eval_dataset=tokenized_dataset[\"validation\"],\n",
    "    data_collator=data_collator,\n",
    "    processing_class=tokenizer,\n",
    "    compute_metrics=compute_metrics,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='14232' max='14232' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [14232/14232 17:55, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Macro Precision</th>\n",
       "      <th>Weighted Precision</th>\n",
       "      <th>Per Class Precision</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.064900</td>\n",
       "      <td>0.061679</td>\n",
       "      <td>0.960881</td>\n",
       "      <td>0.982931</td>\n",
       "      <td>{'PREP+PROADJ': 1.0, 'IN': 1.0, 'PREP+PRO-KS': 0.7692307692307693, 'NPROP': 0.9671410090556274, 'PREP+PROSUB': 0.8518518518518519, 'KC': 0.9891891891891892, 'PROPESS': 0.9976635514018691, 'NUM': 0.9796806966618288, 'PROADJ': 0.9783333333333334, 'PREP+ART': 0.992171405026782, 'KS': 0.9222462203023758, 'PRO-KS': 0.9321663019693655, 'ADJ': 0.9711751662971175, 'ADV-KS': 0.9285714285714286, 'N': 0.9854633555420957, 'PREP': 0.981325618095739, 'PROSUB': 0.9058823529411765, 'PREP+PROPESS': 1.0, 'PDEN': 0.933920704845815, 'V': 0.9967320261437909, 'PREP+ADV': 1.0, 'PCP': 0.9795673076923077, 'CUR': 0.991304347826087, 'ADV': 0.9409282700421941, 'PU': 0.9996508379888268, 'ART': 0.9886986301369863}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.044100</td>\n",
       "      <td>0.059354</td>\n",
       "      <td>0.953689</td>\n",
       "      <td>0.984068</td>\n",
       "      <td>{'PREP+PROADJ': 1.0, 'IN': 0.7857142857142857, 'PREP+PRO-KS': 0.8333333333333334, 'NPROP': 0.976658798846053, 'PREP+PROSUB': 0.8518518518518519, 'KC': 0.9913419913419913, 'PROPESS': 0.9884259259259259, 'NUM': 0.9687943262411347, 'PROADJ': 0.978369384359401, 'PREP+ART': 0.9909502262443439, 'KS': 0.9296703296703297, 'PRO-KS': 0.93058568329718, 'ADJ': 0.9709270433351618, 'ADV-KS': 0.8529411764705882, 'N': 0.9835138387484957, 'PREP': 0.9859751256946282, 'PROSUB': 0.9300411522633745, 'PREP+PROPESS': 1.0, 'PDEN': 0.9432314410480349, 'V': 0.9969849246231156, 'PREP+ADV': 1.0, 'PCP': 0.98661800486618, 'CUR': 0.991304347826087, 'ADV': 0.9371069182389937, 'PU': 0.999825388510564, 'ART': 0.9917355371900827}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.021700</td>\n",
       "      <td>0.065789</td>\n",
       "      <td>0.961825</td>\n",
       "      <td>0.984399</td>\n",
       "      <td>{'PREP+PROADJ': 1.0, 'IN': 1.0, 'PREP+PRO-KS': 0.8333333333333334, 'NPROP': 0.9726134585289515, 'PREP+PROSUB': 0.8518518518518519, 'KC': 0.9870828848223897, 'PROPESS': 0.9953488372093023, 'NUM': 0.9713876967095851, 'PROADJ': 0.9768211920529801, 'PREP+ART': 0.9917593737124022, 'KS': 0.9281045751633987, 'PRO-KS': 0.9281045751633987, 'ADJ': 0.9721006564551422, 'ADV-KS': 0.8529411764705882, 'N': 0.9858678584370093, 'PREP': 0.9867514573396926, 'PROSUB': 0.9338842975206612, 'PREP+PROPESS': 1.0, 'PDEN': 0.9356223175965666, 'V': 0.9964841788046208, 'PREP+ADV': 1.0, 'PCP': 0.9842424242424243, 'CUR': 0.991304347826087, 'ADV': 0.9389233954451346, 'PU': 0.999825388510564, 'ART': 0.9931010693342532}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=14232, training_loss=0.05393620858103992, metrics={'train_runtime': 1076.2112, 'train_samples_per_second': 105.782, 'train_steps_per_second': 13.224, 'total_flos': 1.1014157339000544e+16, 'train_loss': 0.05393620858103992, 'epoch': 3.0})"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Against test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1249' max='1249' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1249/1249 00:24]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.09108009189367294, 'eval_macro_precision': 0.9449901615904162, 'eval_weighted_precision': 0.9815311707574705, 'eval_per_class_precision': {'PREP+PROADJ': 0.9967637540453075, 'IN': 0.5241379310344828, 'PREP+PRO-KS': 0.9152542372881356, 'NPROP': 0.9776452119309262, 'PREP+PROSUB': 0.9038461538461539, 'KC': 0.9869005328596803, 'PROPESS': 0.9937194696441033, 'NUM': 0.9733492442322991, 'PROADJ': 0.9703315881326352, 'PREP+ART': 0.9931466614450754, 'KS': 0.9361532322426177, 'PRO-KS': 0.9279754062362758, 'ADJ': 0.9632103104862332, 'ADV-KS': 0.8558951965065502, 'N': 0.9814008272386118, 'PREP': 0.9811835935181338, 'PROSUB': 0.9385026737967914, 'PREP+PROPESS': 1.0, 'PDEN': 0.898458748866727, 'V': 0.9958356609618607, 'PREP+ADV': 0.9666666666666667, 'PCP': 0.9734953064605191, 'CUR': 0.9932659932659933, 'ADV': 0.9331128261668504, 'PU': 0.9996283771228957, 'ART': 0.9898645973552934}, 'eval_runtime': 25.1627, 'eval_samples_per_second': 396.897, 'eval_steps_per_second': 49.637, 'epoch': 3.0}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('./fine_tuned_model/tokenizer_config.json',\n",
       " './fine_tuned_model/special_tokens_map.json',\n",
       " './fine_tuned_model/vocab.txt',\n",
       " './fine_tuned_model/added_tokens.json',\n",
       " './fine_tuned_model/tokenizer.json')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = trainer.evaluate(\n",
    "    # tokenized_dataset[\"test\"].shuffle(seed=42).select(range(0, 10))\n",
    "    tokenized_dataset[\"test\"]\n",
    ")\n",
    "print(results)\n",
    "\n",
    "model.save_pretrained(\"./fine_tuned_model\")\n",
    "tokenizer.save_pretrained(\"./fine_tuned_model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Against another model trained on the same dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load `lisaterumi/postagger-portuguese` from hugging face and store in a `competitor_model` variable\n",
    "\n",
    "from transformers import BertForTokenClassification\n",
    "\n",
    "competitor_model = BertForTokenClassification.from_pretrained(\n",
    "    \"lisaterumi/postagger-portuguese\"\n",
    ")\n",
    "competitor_model.to(\"cuda\")\n",
    "\n",
    "competitor_tokenizer = AutoTokenizer.from_pretrained(\"lisaterumi/postagger-portuguese\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 37948/37948 [00:06<00:00, 5451.28 examples/s]\n",
      "Map: 100%|██████████| 9987/9987 [00:01<00:00, 6223.02 examples/s]\n",
      "Map: 100%|██████████| 1997/1997 [00:00<00:00, 6049.05 examples/s]\n"
     ]
    }
   ],
   "source": [
    "def tokenize_and_align_labels_for_comparison(examples):\n",
    "    tokenized_inputs = competitor_tokenizer(\n",
    "        examples[\"tokens\"],\n",
    "        truncation=True,\n",
    "        is_split_into_words=True,\n",
    "        padding=\"max_length\",\n",
    "        max_length=128,\n",
    "    )\n",
    "\n",
    "    # Align labels with tokenized inputs\n",
    "    labels = []\n",
    "    for i, label in enumerate(examples[\"labels\"]):\n",
    "        word_ids = tokenized_inputs.word_ids(batch_index=i)\n",
    "        aligned_labels = [\n",
    "            -100 if word_id is None else label[word_id] for word_id in word_ids\n",
    "        ]\n",
    "        labels.append(aligned_labels)\n",
    "\n",
    "    tokenized_inputs[\"labels\"] = labels\n",
    "    return tokenized_inputs\n",
    "\n",
    "\n",
    "tokenized_test_dataset_comparison = tokenized_dataset.map(\n",
    "    tokenize_and_align_labels_for_comparison, batched=True\n",
    ")\n",
    "# tokenized_test_dataset_comparison = tokenized_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/nlp-tp2/.venv/lib/python3.10/site-packages/transformers/training_args.py:1575: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from transformers import TrainingArguments, Trainer\n",
    "\n",
    "# Evaluate the `competitor_model` using the same `compute_metrics` function and the same `tokenized_dataset[\"test\"]` dataset\n",
    "\n",
    "# Define dummy training arguments (just for evaluation)\n",
    "dummy_training_args = TrainingArguments(\n",
    "    output_dir=\"./results\",\n",
    "    logging_dir=\"./logs\",\n",
    "    do_train=False,\n",
    "    do_eval=True,\n",
    "    evaluation_strategy=\"no\",\n",
    "    use_cpu=False\n",
    ")\n",
    "\n",
    "# Create a Trainer for the comparison model\n",
    "competitor_trainer = Trainer(\n",
    "    model=competitor_model,\n",
    "    args=dummy_training_args,\n",
    "    eval_dataset=tokenized_test_dataset_comparison[\"validation\"],\n",
    "    processing_class=competitor_tokenizer,\n",
    "    compute_metrics=compute_metrics,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 10.26021671295166, 'eval_model_preparation_time': 0.003, 'eval_macro_precision': 0.034122055046705034, 'eval_weighted_precision': 0.07739469736230463, 'eval_per_class_precision': {'PREP+PROADJ': 0.0, 'IN': 0.0005425935973955507, 'PREP+PRO-KS': 0.0, 'NPROP': 0.06532663316582915, 'PREP+PROSUB': 0.0005937654626422563, 'KC': 0.05448717948717949, 'PROPESS': 0.01650038372985418, 'NUM': 0.011442141623488774, 'PROADJ': 0.018442622950819672, 'PREP+ART': 0.05470727180698498, 'KS': 0.009498564170532362, 'PRO-KS': 0.022401433691756272, 'ADJ': 0.049019607843137254, 'ADV-KS': 0.002431681333950903, 'N': 0.1430054848500985, 'PREP': 0.08588692274492879, 'PROSUB': 0.08333333333333333, 'PREP+PROPESS': 0.0, 'PDEN': 0.0050009805844283195, 'V': 0.0761904761904762, 'PREP+ADV': 0.0, 'PCP': 0.006422018348623854, 'CUR': 0.0, 'ADV': 0.058823529411764705, 'PU': 0.12311680688710624, 'ART': 0.0}, 'eval_runtime': 21.593, 'eval_samples_per_second': 462.511, 'eval_steps_per_second': 57.843}\n"
     ]
    }
   ],
   "source": [
    "eval_results_comparison = competitor_trainer.evaluate(\n",
    "    tokenized_test_dataset_comparison[\"test\"]\n",
    ")\n",
    "\n",
    "print(eval_results_comparison)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
